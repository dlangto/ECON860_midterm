import pandas
import os
import re
import glob
from bs4 import BeautifulSoup

if not os.path.exists("parsed_files"):
	os.mkdir("parsed_files")

dataset = pandas.DataFrame()

for file_name in glob.glob("html_files/*.html"):


	file = open(file_name, "r")
	soup = BeautifulSoup(file.read(), 'html.parser')
	file.close()

	body = soup.find("body", {"class": "color-0 flex flex-col min-h-screen overflow-x-hidden"})
	main_list = body.find_all("main")
	ghid = []
	num_repo = []
	num_follow = []
	date = []
	for main in main_list:
	
		ghid_list=main.find("div", {"class": "userid"})
		num_repo_list=main.find("div", {"class": "repocount"})
		num_follow_list=main.find("div", {"class": "followercount"})
		date_list=main.find("div", {"class": "membersince"})
		ghid = ghid_list.text
		num_repo = num_repo_list.text
		num_follow = num_follow_list.text
		date = date_list.text

		print(ghid)
		print(num_repo)
		print(num_follow)
		print(date)

		

		dataset = pandas.concat([dataset,
			pandas.DataFrame.from_records([{
				"ghid": ghid,
				"num_repo": num_repo,
				"num_follow": num_follow,
				"date": date
				}])

			])

dataset.to_csv("parsed_files/dataset.csv", index=False)

	

	